{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa8T2jDMYWPh"
      },
      "source": [
        "#Set Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnXTNh5EUpZl"
      },
      "outputs": [],
      "source": [
        "!pip install torchprofile 1>/dev/null\n",
        "!pip install fast-pytorch-kmeans 1>/dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcF3_-2ygIxG",
        "outputId": "265df8cb-c6db-4eeb-ba7e-d2588cf17924"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "WAgGjL5MYrbM"
      },
      "outputs": [],
      "source": [
        "!unzip /content/drive/MyDrive/food_product_main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmrytG8YUpZl"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "import glob\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import random\n",
        "from collections import OrderedDict, defaultdict\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from torch import nn\n",
        "from torch.optim import *\n",
        "from torch.optim.lr_scheduler import *\n",
        "from tqdm.auto import tqdm\n",
        "from torchprofile import profile_macs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrYTzWbRv7iS",
        "outputId": "835226a5-ec5b-4a54-80ad-2b362c8d7970"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7b1b86be7b50>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNTWSSUBYcJS"
      },
      "source": [
        "##Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lV-mkw2cUpZm"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.Normalize((0, 0, 0), (255, 255, 255))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTFGWjk6cXEi",
        "outputId": "0e4a2e75-63e1-46d6-9d9a-c1c7f065b51c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['bada_coconut_original', 'banana_choco_pie', 'bichobi_biscuit', 'binch', 'busor_busor_bulgogi', 'butter_waffle', 'chic_choc_chocolate_cookie', 'choco_hazelnut', 'choco_pie_orion', 'choripong_mushmellow', 'cookie_dasse', 'couque_dasse', 'crown_corn_chip', 'crown_cracker', 'custard_real_cream', 'digest_thin', 'dolaon_sun', 'enaak_chicken', 'gu_on_potato', 'homerun_ball', 'honey_butter_chip', 'hureswi_berry_fresh', 'kobuk_chip_mini', 'kokal_corn', 'korae_bab', 'lotte_choco', 'lotte_choco_abc_cookie', 'lotte_sand_original', 'lotte_teok_pie', 'maccaret_original', 'memorie_donut', 'mini_apple_cookie', 'mu_dukduk_potato', 'nongshim_shrimp_chip', 'nongshim_shrimp_chip_hot', 'nooneul_potato', 'oh_yes_mini', 'omma_sun_pie', 'onion_ring_original', 'oreo_stick_choco', 'peanut_sand', 'phokha_chip_onion', 'phokha_chip_original', 'postick', 'slim_potato_chip', 'strawberry_cookie', 'swing_chip_garlic', 'swing_chip_hot', 'tacco', 'white_hazelnut']\n"
          ]
        }
      ],
      "source": [
        "# Open the text file in read mode\n",
        "with open('/content/drive/MyDrive/product_label.txt', 'r') as file:\n",
        "    # Read all lines from the file and store them as a list\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Strip newline characters from the end of each line and store them in a new list\n",
        "class_set = sorted([line.strip() for line in lines])\n",
        "print(class_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUFlgBU0UpZm"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform, is_each_class):\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        for ext in ['png', 'jpg']:\n",
        "            if is_each_class:\n",
        "              self.image_paths += glob.glob(os.path.join(root_dir, f'*.{ext}'))\n",
        "            else:\n",
        "              self.image_paths += glob.glob(os.path.join(root_dir, '*', f'*.{ext}'))\n",
        "        self.class_lbl = { cls: i for i, cls in enumerate(class_set)}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = read_image(self.image_paths[idx], ImageReadMode.RGB).float()\n",
        "        # img = Image.open(self.image_paths[idx]).convert('RGB')\n",
        "        cls = os.path.basename(os.path.dirname(self.image_paths[idx]))\n",
        "        label = self.class_lbl[cls]\n",
        "\n",
        "        return self.transform(img), torch.tensor(label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMylDYrH6xLp"
      },
      "source": [
        "##Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class VGG(nn.Module):\n",
        "  ARCH = [32, 64, 'M', 128, 128, 'M', 256, 256, 'M', 256, 512, 'M']\n",
        "\n",
        "  def __init__(self) -> None:\n",
        "    super().__init__()\n",
        "\n",
        "    layers = []\n",
        "    counts = defaultdict(int)\n",
        "\n",
        "    def add(name: str, layer: nn.Module) -> None:\n",
        "      layers.append((f\"{name}{counts[name]}\", layer))\n",
        "      counts[name] += 1\n",
        "\n",
        "    in_channels = 3\n",
        "    for x in self.ARCH:\n",
        "      if x != 'M':\n",
        "        # conv-bn-relu\n",
        "        add(\"conv\", nn.Conv2d(in_channels, x, 3, padding=1, bias=False))\n",
        "        add(\"bn\", nn.BatchNorm2d(x))\n",
        "        add(\"relu\", nn.ReLU(True))\n",
        "        in_channels = x\n",
        "      else:\n",
        "        # maxpool\n",
        "        add(\"pool\", nn.MaxPool2d(2))\n",
        "\n",
        "    self.backbone = nn.Sequential(OrderedDict(layers))\n",
        "    self.classifier = nn.Linear(512, len(class_set))\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    x = self.backbone(x)\n",
        "    x = x.mean([2, 3])\n",
        "    x = self.classifier(x)\n",
        "    probabilities = F.softmax(x, dim=1)  # Apply softmax activation to convert logits to probabilities\n",
        "    confidence_percentages = probabilities * 100     # Convert probabilities to percentages\n",
        "\n",
        "    return confidence_percentages"
      ],
      "metadata": {
        "id": "_gEAvfpEFEId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBNmprq27gV7"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "checkpoint_path = \"/content/drive/MyDrive/checkpoint_channel_pruning.pth\" ## modify this to checkpoint path\n",
        "checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n",
        "model = VGG().cuda()\n",
        "model.load_state_dict(checkpoint)\n",
        "recover_model = lambda: model.load_state_dict(checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Test 1"
      ],
      "metadata": {
        "id": "d7Yk3_ZHV_Jt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torchvision.datasets.ImageFolder(root='food_product_main/test', transform=transform)"
      ],
      "metadata": {
        "id": "TJP1E_OyOY1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Create an Excel writer object\n",
        "with pd.ExcelWriter('evaluation_results.xlsx') as writer:\n",
        "\n",
        "    data = []\n",
        "    for class_idx, label in enumerate(class_set):\n",
        "        test_set = CustomDataset(f'food_product_main/test/{label}', transform, True)\n",
        "        predicted_labels = []\n",
        "        true_labels = []\n",
        "        image_ids = []\n",
        "\n",
        "        # Iterate over the validation set\n",
        "        for image_id, (inputs, targets) in enumerate(test_set):\n",
        "            # Move inputs to GPU if available\n",
        "            inputs = inputs.cuda()\n",
        "\n",
        "            # Perform inference\n",
        "            with torch.no_grad():\n",
        "                outputs = model(inputs.unsqueeze(0))  # Add batch dimension\n",
        "                predicted_label = outputs.argmax(dim=1).item()\n",
        "\n",
        "            # Append predicted and true labels to the list\n",
        "            predicted_labels.append(predicted_label)\n",
        "            true_labels.append(targets.item())  # Convert tensor to item\n",
        "            image_ids.append(image_id + 1)  # Image ID starting from 1\n",
        "\n",
        "        # Convert predicted and true labels to numpy arrays\n",
        "        predicted_labels = np.array(predicted_labels)\n",
        "        true_labels = np.array(true_labels)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        accuracy = (predicted_labels == true_labels).mean()\n",
        "\n",
        "        # Store detailed results in a DataFrame\n",
        "        results = []\n",
        "        for img_id, true, pred in zip(image_ids, true_labels, predicted_labels):\n",
        "            results.append([img_id, label, class_set[pred], class_set[true], accuracy])\n",
        "\n",
        "        df = pd.DataFrame(results, columns=['image_id', 'class_label', 'predicted_label', 'true_label', 'accuracy'])\n",
        "\n",
        "        # Write detailed results to an Excel sheet\n",
        "        df.to_excel(writer, sheet_name=f'{label}', index=False)\n",
        "\n",
        "        # Calculate confusion matrix and classification report\n",
        "        conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "        report = classification_report(true_labels, predicted_labels, output_dict=True)\n",
        "\n",
        "        # Extract precision and recall for the current class\n",
        "        class_str = str(class_idx)\n",
        "        if class_str in report:\n",
        "            precision = report[class_str]['recall']\n",
        "            support = report[class_str]['support']\n",
        "            true_positives = int(support * precision)\n",
        "            false_positives = support - true_positives\n",
        "            total_images = len(true_labels)  # Total number of images tested for this class\n",
        "            precision_percentage = f\"{precision * 100:.2f}%\"\n",
        "\n",
        "            data.append([class_set[class_idx], total_images, true_positives, false_positives, precision_percentage])\n",
        "        else:\n",
        "            data.append([class_set[class_idx], 0, 0, 0, 0.0, 0.0])\n",
        "\n",
        "    # Create a DataFrame for the summary metrics\n",
        "    df_summary = pd.DataFrame(data, columns=['Class', 'Test Image', 'True', 'False', 'Precision'])\n",
        "\n",
        "    # Save the summary metrics to the same Excel file\n",
        "    df_summary.to_excel(writer, sheet_name='Class_Metrics', index=False)\n",
        "\n",
        "print(\"Results saved to evaluation_results.xlsx\")\n"
      ],
      "metadata": {
        "id": "gJBeDMdOKhrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Test 2"
      ],
      "metadata": {
        "id": "ipYGxTyjWBZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torchvision.datasets.ImageFolder(root='food_product_main', transform=transform)\n",
        "test_set = CustomDataset('food_product_main/test', transform, False)"
      ],
      "metadata": {
        "id": "X-vWzftbV9f2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Create a list to store predicted and true labels\n",
        "predicted_labels = []\n",
        "true_labels = []\n",
        "\n",
        "# Iterate over the validation set\n",
        "for inputs, targets in test_set:\n",
        "    # Move inputs to GPU if available\n",
        "    inputs = inputs.cuda()\n",
        "\n",
        "    # Perform inference\n",
        "    with torch.no_grad():\n",
        "        outputs = model(inputs.unsqueeze(0))  # Add batch dimension\n",
        "        predicted_label = outputs.argmax(dim=1).item()\n",
        "\n",
        "    # Append predicted and true labels to the list\n",
        "    predicted_labels.append(predicted_label)\n",
        "    true_labels.append(targets.item())\n",
        "\n",
        "# Convert predicted and true labels to numpy arrays\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "true_labels = np.array(true_labels)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Visualize the confusion matrix\n",
        "# plt.figure(figsize=(10, 8))\n",
        "# plt.imshow(conf_matrix, cmap='Blues', interpolation='nearest')\n",
        "# plt.colorbar()\n",
        "# plt.title('Confusion Matrix')\n",
        "# plt.xlabel('Predicted Label')\n",
        "# plt.ylabel('True Label')\n",
        "# plt.show()\n",
        "\n",
        "# Specify the classes you are interested in (indices of the classes)\n",
        "specific_classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
        "\n",
        "# Generate the classification report as a dictionary\n",
        "report = classification_report(true_labels, predicted_labels, output_dict=True)\n",
        "\n",
        "# Prepare data for the DataFrame\n",
        "data = []\n",
        "\n",
        "for class_idx in specific_classes:\n",
        "    class_str = str(class_idx)\n",
        "    if class_str in report:\n",
        "        precision = report[class_str]['precision']\n",
        "        recall = report[class_str]['recall']\n",
        "        support = report[class_str]['support']\n",
        "        true_positives = int(support * recall)\n",
        "        false_negatives = support - true_positives\n",
        "        total_images = support  # Total number of actual images in this class\n",
        "        false_positives = sum((true_labels == class_idx) & (predicted_labels != class_idx)) # Number of incorrect predictions for this class\n",
        "\n",
        "        data.append([class_idx, total_images, true_positives, false_positives, precision, recall])\n",
        "    else:\n",
        "        data.append([class_idx, 0, 0, 0, 0.0, 0.0])\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data, columns=['class', 'test_image', 'True', 'False', 'precision', 'recall'])\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "df.to_excel('class_metrics.xlsx', index=False)\n",
        "\n",
        "print(\"Results saved to class_metrics.xlsx\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m71I8jP_JvQd",
        "outputId": "7acfa38f-a25f-4151-ad31-32348106d695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to class_metrics.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTXz0F8rkyWp"
      },
      "source": [
        "#Model Inference Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnNxlUNmkzs2",
        "outputId": "2c9ae1b5-98a6-427a-b34b-e9391110f9b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  8   3 128 128]\n",
            "[ 8 50]\n",
            "[{'name': 'serving_default_input:0', 'index': 0, 'shape': array([  8,   3, 128, 128], dtype=int32), 'shape_signature': array([  8,   3, 128, 128], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# Load the TFLite model and allocate tensors\n",
        "interpreter = tf.lite.Interpreter(model_path=\"model_channel_pruning.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "print(input_details[0]['shape'])\n",
        "print(output_details[0]['shape'])\n",
        "print(input_details)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjFvD2NIk2r8"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess the image\n",
        "image_path = \"/content/f29f697d-e928-4b73-b43b-0f7333b81e34.jpg\"\n",
        "image = Image.open(image_path)\n",
        "image = image.resize((input_details[0]['shape'][2], input_details[0]['shape'][3]))\n",
        "image = np.array(image, dtype=np.float32) / 255 # Normalize pixel values to [0, 1]\n",
        "\n",
        "image = np.array([image for i in range(8)])\n",
        "image = np.transpose(image, (0, 3, 1, 2))\n",
        "\n",
        "index = input_details[0]['index']\n",
        "\n",
        "# Set input tensor\n",
        "interpreter.set_tensor(index, image)\n",
        "\n",
        "# Perform inference\n",
        "interpreter.invoke()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWdIHVD4WG5C",
        "outputId": "2b869e3e-24dc-454e-f74c-164d417afba0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class: tacco - Confidence: 41.797176361083984 - Percentage: 100.00%\n",
            "Class: chic_choc_chocolate_cookie - Confidence: 7.594037055969238 - Percentage: 0.00%\n",
            "Class: nongshim_shrimp_chip - Confidence: 6.517587661743164 - Percentage: 0.00%\n",
            "Class: kobuk_chip_mini - Confidence: 4.528082370758057 - Percentage: 0.00%\n",
            "Class: banana_choco_pie - Confidence: 3.9245169162750244 - Percentage: 0.00%\n"
          ]
        }
      ],
      "source": [
        "# Get the output tensor\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "# print(output_data[0][2])\n",
        "predicted_class = np.argmax(output_data)\n",
        "# print(predicted_class)\n",
        "\n",
        "# Load labels (if available)\n",
        "labels = None\n",
        "labels_path = 'product_label.txt'  # Replace with your label file path\n",
        "if labels_path:\n",
        "    with open(labels_path, 'r') as f:\n",
        "        labels = [line.strip() for line in f.readlines()]\n",
        "\n",
        "# Post-process inference results\n",
        "top_classes = output_data[0].argsort()[-5:][::-1]  # Get top 5 classes with highest scores\n",
        "\n",
        "# Print detected objects and confidence scores\n",
        "for class_id in top_classes:\n",
        "    confidence = output_data[0][class_id]\n",
        "    probabilities = (np.exp(confidence) / np.sum(np.exp(output_data[0]))) * 100\n",
        "    print(\"Class: {} - Confidence: {:} - Percentage: {:.2f}%\".format(labels[class_id], confidence, probabilities))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "YTXz0F8rkyWp"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}