{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Prerequisites\n",
        "\n",
        "Upload:\n",
        "- headers.json\n",
        "- product_label.txt\n",
        "- product_review_links.txt"
      ],
      "metadata": {
        "id": "kXG_pK1_ByW0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Initialization"
      ],
      "metadata": {
        "id": "oHWYuc7ECPWT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cN7QicC5Bg8V",
        "outputId": "ce73c07b-d298-4887-ac9a-1fc3ed9f66a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.2.2)\n",
            "Collecting bs4\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4) (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4) (2.5)\n",
            "Installing collected packages: bs4\n",
            "Successfully installed bs4-0.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install openpyxl\n",
        "!pip install requests\n",
        "!pip install bs4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup as bs\n",
        "from pathlib import Path\n",
        "from typing import Optional,Union,Dict,List\n",
        "import time\n",
        "import os\n",
        "import requests as requests\n",
        "import json\n",
        "\n",
        "path = Path('food_product')\n",
        "path_train = Path('food_product/train')\n",
        "path_test = Path('food_product/test')"
      ],
      "metadata": {
        "id": "2U7gyF8ZBmnr"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_headers(\n",
        "    key: str,\n",
        "    default_value: Optional[str] = None\n",
        "    )-> Dict[str,Dict[str,str]]:\n",
        "    \"\"\" Get Headers \"\"\"\n",
        "    JSON_FILE : str = 'headers.json'\n",
        "\n",
        "    with open(JSON_FILE,'r',encoding='UTF-8') as file:\n",
        "        headers : Dict[str,Dict[str,str]] = json.loads(file.read())\n",
        "\n",
        "    try :\n",
        "        return headers[key]\n",
        "    except:\n",
        "        if default_value:\n",
        "            return default_value\n",
        "        raise EnvironmentError(f'Set the {key}')\n",
        "\n",
        "def download_images(dest_train: str, dest_test: str, results: List):\n",
        "    count = 0\n",
        "    for i in range(len(results) - 3):\n",
        "      # print(len(results[i]))\n",
        "      for x in results[i]:\n",
        "          try:\n",
        "            r = requests.get(x).content\n",
        "          except:\n",
        "            pass\n",
        "          with open(f\"{dest_train}/images-{count+1}.jpg\", \"wb+\") as f:\n",
        "            f.write(r)\n",
        "          count += 1\n",
        "    for i in range(10, len(results)):\n",
        "      # print(len(results[i]))\n",
        "      for x in results[i]:\n",
        "          try:\n",
        "            r = requests.get(x).content\n",
        "          except:\n",
        "            pass\n",
        "          with open(f\"{dest_test}/images-{count+1}.jpg\", \"wb+\") as f:\n",
        "            f.write(r)\n",
        "          count += 1\n",
        "\n",
        "    print(count)\n",
        "\n",
        "class CoupangImageReview:\n",
        "    @staticmethod\n",
        "    def get_product_code(url: str)-> str:\n",
        "        #split to get the product Id\n",
        "        prod_code : str = url.split('products/')[-1].split('?')[0]\n",
        "        return prod_code\n",
        "\n",
        "    def __init__(self)-> None:\n",
        "        self.__headers : Dict[str,str] = get_headers(key='headers')\n",
        "\n",
        "    def main(self, link: str, page_count: int):\n",
        "        URL : str = link\n",
        "\n",
        "        prod_code : str = self.get_product_code(url=URL)\n",
        "\n",
        "        URLS : List[str] = [f'https://www.coupang.com/vp/product/reviews?productId={prod_code}&page={page}&size=5&sortBy=ORDER_SCORE_ASC&ratings=&q=&viRoleCode=3&ratingSummary=true' for page in range(1, page_count + 1)]\n",
        "\n",
        "        self.__headers['referer'] = URL\n",
        "\n",
        "        with requests.Session() as session:\n",
        "            return [self.fetch(url=url, session=session) for url in URLS]\n",
        "\n",
        "    def fetch(self, url:str, session):\n",
        "        save_data = []\n",
        "\n",
        "        with session.get(url=url, headers=self.__headers) as response :\n",
        "            html = response.text\n",
        "            soup = bs(html,'html.parser')\n",
        "\n",
        "            article_lenth = len(soup.select('article.sdp-review__article__list'))\n",
        "\n",
        "            for idx in range(article_lenth):\n",
        "                articles = soup.select('article.sdp-review__article__list')\n",
        "\n",
        "                img_con = articles[idx].select_one('div.sdp-review__article__list__attachment')\n",
        "                img_list = img_con.select('div.sdp-review__article__list__attachment__list')\n",
        "                if len(img_list) > 0:\n",
        "                  for i in range(len(img_list)):\n",
        "                    img_link = img_list[i].select_one('img.sdp-review__article__list__attachment__img')\n",
        "                    if img_link == None or img_link.attrs['src'] == '':\n",
        "                        img_link = '-'\n",
        "                    else:\n",
        "                        img_link = img_link.attrs['src']\n",
        "                        save_data.append(img_link)\n",
        "                else:\n",
        "                    img_link = '-'\n",
        "            time.sleep(1)\n",
        "\n",
        "            return save_data\n",
        "\n",
        "    @staticmethod\n",
        "    def clear_console() -> None:\n",
        "        command: str = 'clear'\n",
        "        if os.name in ('nt','dos'):\n",
        "            command = 'cls'\n",
        "        os.system(command=command)"
      ],
      "metadata": {
        "id": "1aWquHVvCYwK"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GetReviewImages:\n",
        "    @staticmethod\n",
        "    def get_images(label: str, link: str, page_count: int)-> None:\n",
        "        results = CoupangImageReview().main(link, page_count)\n",
        "        dest_train = (path_train/label)\n",
        "        dest_test = (path_test/label)\n",
        "\n",
        "        try:\n",
        "            os.mkdir(dest_train)\n",
        "            os.mkdir(dest_test)\n",
        "        except:\n",
        "            pass\n",
        "        download_images(dest_train, dest_test, results)"
      ],
      "metadata": {
        "id": "OJVXKvXsCcmB"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Main Function"
      ],
      "metadata": {
        "id": "C1il3EQsCgI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    product_review_links = []\n",
        "    product_labels = []\n",
        "    # Read product label\n",
        "    with open('product_label.txt', 'r') as file:\n",
        "        for line in file:\n",
        "            product_labels.append(line.strip())\n",
        "\n",
        "    with open('product_review_links.txt', 'r') as file:\n",
        "        for line in file:\n",
        "            product_review_links.append(line.strip())\n",
        "\n",
        "    page_count = 13\n",
        "    try:\n",
        "        os.mkdir(path)\n",
        "        os.mkdir(path_train)\n",
        "        os.mkdir(path_test)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    for idx in range(len(product_review_links)):\n",
        "        label = product_labels[idx]\n",
        "        link = product_review_links[idx]\n",
        "        GetReviewImages.get_images(label, link, page_count)"
      ],
      "metadata": {
        "id": "OsQpc13YBs-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "folder_path = \"/content/food_product\"\n",
        "\n",
        "zip_path = \"/content/food_product\"\n",
        "\n",
        "shutil.make_archive(zip_path, 'zip', folder_path)\n",
        "\n",
        "from google.colab import files\n",
        "files.download(zip_path)"
      ],
      "metadata": {
        "id": "Wzb7F8DDUsFv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}